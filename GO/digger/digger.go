package digger

import (
	"container/list"
	"errors"
	"fmt"
	"math/rand"
	"net/http"
	"net/http/cookiejar"
	"net/url"
	"os"
	"regexp"
	"strings"
	"sync"
	"time"

	"github.com/astaxie/beego/logs"
)

//ä¸€äº›å…¬ç”¨é…ç½®ã€å‚æ•°
var (
	totalSizeLimit int    //å›¾ç‰‡æ€»å¤§å°é™åˆ¶,MB
	minSizeLimit   int    //æ–‡ä»¶å¤§å°æœ€å°å€¼ï¼ŒKB
	maxSizeLimit   int    //æ–‡ä»¶å¤§å°æœ€å¤§å€¼ï¼ŒKB
	numberLimit    int    //å›¾ç‰‡ä¸‹è½½æ•°é‡é™åˆ¶
	pageLimit      int    //çˆ¬å–é¡µé¢æ•°é‡é™åˆ¶(æµ‹è¯•ç”¨)
	threadLimit    int    //ä¸‹è½½å¼•æ“æ•°é‡é™åˆ¶
	waitTimeLimit  int    //æœ€é•¿ç­‰å¾…æ—¶é—´ï¼Œå•ä½ç§’
	intervalTime   int    //ç­‰å¾…é—´éš”ï¼Œç§’
	savePath       string //ä¿å­˜è·¯å¾„
	method         string //ç­–ç•¥ï¼šBFS\DFS\FOR\LIST
	baseUrl        string //BFS\DFSè½¦è£‚ä¸‹çš„ç½‘é¡µå…¥å£é“¾æ¥ï¼Œæˆ–FORç­–ç•¥ä¸‹çš„æ¨¡æ¿, listç­–ç•¥ä¸‹æ”¾urlåˆ—è¡¨
	linkKey        string //è½¬è·³é“¾æ¥å…³é”®å­—
	targetKey      string //åŒ…å«ç›®æ ‡å›¾ç‰‡é“¾æ¥çš„è¡¨æƒ…å…³é”®å­—
	startPoint     int    //FORç­–ç•¥ä¸‹çš„å˜é‡èµ·ç‚¹(åŒ…å«)
	endPoint       int    //FORç­–ç•¥ä¸‹çš„å˜è„¸ç»ˆç‚¹(åŒ…å«)
)

//ä¸€äº›ç»Ÿè®¡æ•°å€¼
var (
	totalBytes  int       //å·²ä¸‹è½½å›¾ç‰‡çš„æ€»å¤§å° (ç»´æŠ¤ä½ç½®ï¼šDownLoadImg())
	totalNumber int       //å·²ä¸‹è½½å›¾ç‰‡çš„ä¸­æ•°é‡ (ç»´æŠ¤ä½ç½®ï¼šgetName())
	pageNumber  int       //å·²ç»è®¿é—®çš„é¡µé¢æ•°é‡ (ç»´æŠ¤ä½ç½®ï¼šgetHtmlCodeOfUrl())
	tmpBytes    int       //å•ä½æ—¶é—´å†…ä¸‹è½½å›¾ç‰‡çš„æ€»å¤§å° (ç»´æŠ¤ä½ç½®ï¼šgetReportString() & DownLoadImg() )
	totalTime   int       //æ€»è¿è¡Œæ—¶é—´ï¼Œç§’
	percentage  int       //ä»»åŠ¡è¿›åº¦ï¼Œ(ç™¾åˆ†ä¹‹å¤šå°‘)
	lastTime    time.Time //ä¸Šæ¬¡ç»Ÿè®¡ä¸‹è½½é€Ÿåº¦çš„æ—¶é—´
	startTime   time.Time //ä¸Šæ¬¡ç‚¹å‡»å¼€å§‹æˆ–ç»§ç»­çš„æ—¶é—´
)

//ä¸€äº›å…¨å±€æ•°æ®å®¹å™¨
var (
	foundPageList *list.List      //å·²ç»å‘ç°çš„ç½‘é¡µé“¾æ¥åœ°å€åˆ—è¡¨
	lastPageEle   *list.Element   //ä¼˜å…ˆå¾…å¤„ç†çš„ç½‘é¡µåœ°å€
	foundImgList  *list.List      //å·²ç»å‘ç°çš„å›¾ç‰‡é“¾æ¥åˆ—è¡¨
	lastImgEle    *list.Element   //ä¼˜å…ˆå¾…å¤„ç†çš„å›¾ç‰‡é“¾æ¥
	pageUrlMap    map[string]bool //è®°å½•å·²ç»è®¿é—®è¿‡çš„é¡µé¢é¿å…é‡å¤çˆ¬å–
	imgUrlMap     map[string]bool //è®°å½•å·²ç»ä¸‹è½½è¿‡çš„å›¾ç‰‡é¿å…é‡å¤ä¸‹è½½
)

//ä¸€äº›å…¨å±€å˜é‡æˆ–å¯¹è±¡
var (
	diggerState     int32        //å·¥ä½œçŠ¶æ€ï¼š0æœªå¼€å§‹æˆ–å·²ç»ˆæ­¢ï¼Œ1è¿è¡Œä¸­ï¼Œ2æš‚åœä¸­
	downloadState   int32        //å›¾ç‰‡ä¸‹è½½åŠŸèƒ½çŠ¶æ€ï¼š0æœªå¯åŠ¨ï¼Œ1å·²å¯åŠ¨
	reporterState   int          //å·²å¯åŠ¨çš„ç»Ÿè®¡æ•°æ®å‘é€å™¨çš„æ•°é‡
	randMachine     *rand.Rand   //ç”¨æˆ·åˆ›å»ºéšæœºæ•°çš„å¯¹è±¡
	mainClient      *http.Client //ç”¨äºå‘é€httpè¯·æ±‚çš„å®¢æˆ·ç«¯å¯¹è±¡
	getNameMutex    *sync.Mutex  //åŒæ­¥é”ï¼Œç”Ÿæˆéšæœºæ•°æ—¶ç”¨
	sendMsgMutex    *sync.Mutex  //å‘é€æ¶ˆæ¯åŒæ­¥é”
	updataSizeMutex *sync.Mutex  //åŒæ­¥é”ï¼Œæ›´æ–°å·²ä¸‹è½½å›¾ç‰‡å¤§å°æ—¶ç”¨
	msgChan         *chan string //ç”¨äºå°†æ¶ˆæ¯ç›´æ¥é€šè¿‡bridgeæ¥å®ç°å‘é€åˆ°ç®¡é“
)

//ä¸€äº›å…¨å±€æ­£åˆ™è¡¨è¾¾å¼å¯¹è±¡
var (
	regexpFindAllATag   *regexp.Regexp //æ‰¾å‡ºæ‰€æœ‰çš„ <a> æ ‡ç­¾
	regexpFindAllImgTag *regexp.Regexp //æ‰¾å‡ºæ‰€æœ‰çš„ <img> æ ‡ç­¾
	regexpIsImgUrl      *regexp.Regexp //åˆ¤æ–­æ˜¯å¦ä¸€ä¸ªå›¾ç‰‡é“¾æ¥
)

func init() {
	initStaticValue()
	diggerState = 0 //æœªå¼€å§‹
	downloadState = 0
	reporterState = 0
	pageLimit = 4000
	msgChan = nil
	randMachine = rand.New(rand.NewSource(time.Now().UnixNano()))
	mainClient = new(http.Client)
	foundPageList = list.New()
	foundImgList = list.New()
	pageUrlMap = make(map[string]bool)
	imgUrlMap = make(map[string]bool)
	if tmpJar, err := cookiejar.New(nil); err != nil {
		logs.Warn("Create a cookieJar fail: err=%v", err)
		tmpJar = nil
	} else {
		mainClient.Jar = tmpJar
	}
	//åˆå§‹åŒ–åŒæ­¥é”
	updataSizeMutex = new(sync.Mutex)
	getNameMutex = new(sync.Mutex)
	sendMsgMutex = new(sync.Mutex)
	//æœªç»æµ‹è¯•ä¿®æ”¹ä»¥ä¸‹æ­£åˆ™å¯èƒ½å¼•å‘panic
	regexpFindAllATag = regexp.MustCompile(`<a [^>]*href=[^>]*>`)
	regexpFindAllImgTag = regexp.MustCompile(`<img [^>]*src=[^>]*>`)
	regexpIsImgUrl = regexp.MustCompile(`https?://[^ "]*.(jpg|png|jpeg|gif|ico)$`)
}

//å¼€å§‹å·¥ä½œï¼Œconfig ä¸ºæŒ‡å®šå·¥ä½œæ–¹å¼çš„é…ç½®è¯´æ˜
func StartDigger(config string) error {
	var err error
	if err := setUpConfig(config); err != nil { //åˆå§‹åŒ–
		logs.Error("Setupconfig fail: %v", err)
		return err
	}
	if suc, err := canVisitBaseUrl(); !suc { //æ£€æŸ¥ç½‘ç»œçŠ¶æ€
		logs.Warn("Can't not visit BaseUrl, err=%v", err)
		return err
	}
	initStaticValue()
	err = ContinueDigger() //å¼€å§‹å·¥ä½œ
	if err != nil {
		logs.Error("Start or continue fail: %v", err)
		return err
	}
	return nil
}

//è®¾ç½®ç”¨äºè¿”å›å›¾ç‰‡ä¸‹è½½æƒ…å†µçš„ç®¡é“
func SetupMsgChan(newChan *chan string) error {
	if newChan == nil {
		return errors.New("newChan is nil")
	}
	if msgChan != nil {
		return errors.New("setup msgChan fail because msgChan not nil")
	}
	msgChan = newChan
	logs.Info("msgChan have been setup")
	return nil
}

//æš‚åœå·¥ä½œ,ä¿ç•™çŠ¶æ€
func PauseDigger() error {
	diggerState = 2   //åœæ­¢ç»§ç»­å‘æ˜ç½‘é¡µ
	reporterState = 0 //åœæ­¢å‘é€æŠ¥å‘Š
	downloadState = 2 //æš‚åœç»§ç»­ä¸‹è½½å›¾ç‰‡
	return nil
}

//ç»ˆæ­¢å·¥ä½œæ¸…æ¥šçŠ¶æ€ ğŸ¢
func StopDigger() error {
	diggerState = 0
	reporterState = 0    //ç»“æŸå‘é€æŠ¥å‘Šä»»åŠ¡
	downloadState = 0    //ç»“æŸå›¾ç‰‡ä¸‹è½½ä»»åŠ¡
	var totalSize string //ç”¨äºè¡¨ç¤ºä¸‹è½½æ–‡ä»¶æ€»å¤§å°çš„å­—ç¬¦ä¸²
	if totalBytes < 1<<10 {
		totalSize = fmt.Sprintf("%dB", totalBytes)
	} else if totalBytes < 1<<20 {
		totalSize = fmt.Sprintf("%dKB", totalBytes>>10)
	} else {
		totalSize = fmt.Sprintf("%dMB", totalBytes>>20)
	}
	logs.Info("StopDigger() have been called, data have been clear")
	logs.Info("Achievement: PageListLen=%d \t imagesListLen=%d \t PageNumber=%d \t imagesNumber=%d \t totalSize=%s",
		foundPageList.Len(),
		foundImgList.Len(),
		pageNumber,
		totalNumber,
		totalSize,
	)
	//æ¸…é™¤æ•°æ®
	foundPageList.Init()
	foundImgList.Init()
	imgUrlMap = make(map[string]bool)
	pageUrlMap = make(map[string]bool)
	initStaticValue()
	return nil
}

//å¼€å§‹æˆ–ç»§ç»­å·¥ä½œ
func ContinueDigger() error {
	var err error
	switch diggerState {
	case 1: //æ­£åœ¨å·¥ä½œä¸­
		err = errors.New("Can not start or continue because digger is running")
	case 0, 2:
		if method == "BFS" {
			err = runBFS()
		} else if method == "DFS" {
			err = runDFS()
		} else if method == "FOR" {
			err = runFOR()
		} else if method == "LIST" {
			err = runLIST()
		} else {
			err = errors.New("Unexpect method: mthod=" + method)
		}
		//å¯åŠ¨æˆ–æ¢å¤å›¾ç‰‡ä¸‹è½½ä»¥åŠå‘é€ç»Ÿè®¡æ•°æ®çš„åŠŸèƒ½
		if err == nil {
			go setupReporter()
			go WaitImgAndDownload(threadLimit)
		}
	default:
		err = fmt.Errorf("Unknow diggerState: diggerState=%d", diggerState)
	}
	if err != nil {
		logs.Error(err)
		return err
	}
	return nil
}

//============================= åŠŸèƒ½æµ‹è¯• =============================
func TEST1() {
	for i := 0; i < 30; i++ {
		err := sendResult("http:itisimgurl.com/testting", "OK", "test.jpg", i*10240)
		if err != nil {
			logs.Error(err)
		}
		time.Sleep(time.Millisecond * 100)
	}
	time.Sleep(time.Second)
	os.Exit(1)
}

//============================= æ‰§è¡Œç­–ç•¥ =====================

//å¼€å§‹æˆ–ç»§ç»­BFSç­–ç•¥å·¥ä½œ
func runBFS() error {
	var err error
	if diggerState != 0 {
		return errors.New("diggerState not 0")
	}
	if foundPageList.Len() < 1 {
		return errors.New("foundPageList is empty")
	}
	//å¼€å§‹BFS
	diggerState = 1
	go func() {
		for diggerState == 1 {
			//åˆ°è¾¾åœæ­¢æ¡ä»¶ï¼Œæ³¨æ„ä¸ä»…è¦åœæ­¢diggerï¼Œè€Œä¸”è¦åœæ­¢reporter å’Œ downloader
			if isShouldSopt() {
				logs.Info("The exit condition is triggered")
				sendMessage("function", "auto_stop") //ğŸ‰
				StopDigger()
				break
			}
			pageHtml, url := "", "" //pageHtmlæš‚å­˜é¡µé¢çš„htmlä»£ç 
			var imgLink []string    //æš‚å­˜å›¾ç‰‡é“¾æ¥
			var pagelink []string   //æš‚å­˜è½¬è·³é“¾æ¥
			//å–å‡ºé¡µé¢é˜Ÿåˆ—çš„ç¬¬ä¸€ä¸ªå…ƒç´ 
			if url = lastPageEle.Value.(string); url == "" {
				logs.Error("lastPageEle is empty string")
				goto end
			}
			//å‘é€httpè¯·æ±‚è·å–é¡µé¢ä»£ç 
			if err = getHtmlCodeOfUrl(url, &pageHtml); err != nil {
				logs.Warn("getHtmlCodeOfUrl fail: url=%s  err=%v", url, err)
				goto end
			}
			//ç›´æ¥è¿‡æ»¤æ‰é•¿åº¦å¤ªçŸ­çš„é¡µé¢ä»£ç 
			if len(pageHtml) < 1000 {
				logs.Info("pageHtml not used because too short. length=%d", len(pageHtml))
				goto end
			}
			//è·å–æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„å›¾ç‰‡é“¾æ¥ï¼Œå¹¶åŠ å…¥åˆ°å›¾ç‰‡é˜Ÿåˆ—
			if err = getAllSpeciicImgLink(url, &pageHtml, &imgLink); err != nil {
				logs.Warn("Get specific images link from pageHtml fail: err=%v", err)
			} else if len(imgLink) == 0 {
				logs.Warn("No images link found in pageHtml, url=%v", url)
			} else {
				for _, value := range imgLink {
					if imgUrlMap[value] == false {
						foundImgList.PushBack(value)
						imgUrlMap[value] = true
						// logs.Debug("new img: %s", value)
					}
				}
			}
			//è·å–ç¬¦åˆè½¬è·³æ¡ä»¶çš„é“¾æ¥
			if err = getAllSpeciicPageLink(url, &pageHtml, &pagelink); err != nil {
				logs.Error("Get specific pagelink from pageHtml fail: err=%v", err)
			} else if len(pagelink) == 0 {
				logs.Warn("No pagelink found in pageHtml, url=%v", url)
			} else {
				for _, value := range pagelink {
					if pageUrlMap[value] == false {
						foundPageList.PushBack(value)
						pageUrlMap[value] = true
						// logs.Debug("new page: %s", value)
					}
				}
			}
			logs.Info("a page is ok: url:%s	pageLen:%d	imgNum:%d	linkNum:%d", url, len(pageHtml), len(imgLink), len(pagelink))
		end:
			//è‹¥é¡µé¢é˜Ÿåˆ—å·²ç»åˆ°åº•ï¼Œåˆ™BFSç»“æŸ
			if lastPageEle == foundPageList.Back() {
				logs.Info("last element of foundPageList have been used...")
				break
			} else {
				lastPageEle = lastPageEle.Next()
			}
			time.Sleep(time.Second * time.Duration(intervalTime))
		}
		diggerState = 0
		logs.Info("gorounting in runBFS() go to the end, imgList's length=%d   pageList's length=%d", foundImgList.Len(), foundPageList.Len())
	}()
	return nil
}

//å¼€å§‹æˆ–ç»§ç»­DFSç­–ç•¥å·¥ä½œ  ğŸ¢
func runDFS() error {
	logs.Warn("TODO: runDFS()")
	return nil
}

//å¼€å§‹æˆ–ç»§ç»­FORç­–ç•¥å·¥ä½œ  ğŸ¢
func runFOR() error {
	logs.Warn("TODO: runFOR()")
	return nil
}

//å¼€å§‹æˆ–ç»§ç»­LISTç­–ç•¥å·¥ä½œ ğŸ¢
func runLIST() error {
	logs.Warn("TODO: runLIST()")
	return nil
}

//======================= æ¬¡è¦æµç¨‹ ==============

//å¤„ç†æŒ‡å®šå·¥ä½œæ–¹å¼çš„é…ç½®å­—ç¬¦ä¸²ï¼Œå°†å…¶ä¸­çš„ä¿¡æ¯è§£æåˆ°å…¨å±€å˜é‡ä¹‹ä¸­
//ä»…åœ¨ç¬¬ä¸€å¼€å§‹ã€ç»“æŸåé‡æ–°å¼€å§‹æ—¶è°ƒç”¨ï¼Œæš‚åœåç»§ç»­ä¸è°ƒç”¨
func setUpConfig(config string) error {
	sucNum, err := fmt.Sscanf(config, "%s %s %d %d %d %d %d %d %d %s %s %s %d %d",
		&method,
		&savePath,
		&totalSizeLimit,
		&numberLimit,
		&threadLimit,
		&minSizeLimit,
		&maxSizeLimit,
		&waitTimeLimit,
		&intervalTime,
		&baseUrl,
		&linkKey,
		&targetKey,
		&startPoint,
		&endPoint)
	if sucNum != 14 || err != nil {
		logs.Error("Scanf config from given string fail, err=", err)
		return errors.New("syntax worng")
	}
	if checkBaseConf() == false {
		err = errors.New("config checking not pass")
		logs.Error(err)
		return err
	}
	mainClient.Timeout = time.Second * time.Duration(waitTimeLimit)
	if len(pageUrlMap) > 0 {
		pageUrlMap = make(map[string]bool)
	}
	if len(imgUrlMap) > 0 {
		imgUrlMap = make(map[string]bool)
	}
	if foundPageList.Len() > 0 {
		foundPageList.Init()
	}
	if foundImgList.Len() > 0 {
		foundImgList.Init()
	}
	if method == "BFS" || method == "DFS" {
		lastPageEle = foundPageList.PushBack(baseUrl)
	}
	lastImgEle = foundImgList.Front()
	targetKey = strings.Replace(targetKey, "&empty", "", -1)
	targetKey = strings.Replace(targetKey, "&space", " ", -1)
	linkKey = strings.Replace(linkKey, "&empty", "", -1)
	linkKey = strings.Replace(linkKey, "&space", " ", -1)
	return nil
}

//æ¯æ¬¡ä¿å­˜å›¾ç‰‡æˆåŠŸåé€šè¿‡ç®¡é“å‘qtç«¯å‘é€ä¸€æ¡æŠ¥å‘Š
//size çš„å•ä½ä¸ºå­—èŠ‚
func sendResult(imgUrl string, result string, saveName string, size int) error {
	if imgUrl == "" || strings.Contains(imgUrl, " ") {
		return errors.New("imgUrl is null or contain space")
	}
	if saveName == "" || strings.Contains(saveName, " ") {
		return errors.New("saveName is null or contain space")
	}
	if result == "" || strings.Contains(result, " ") {
		return errors.New("result is null or contain space")
	}
	if size < 0 {
		return errors.New("size illeagle")
	}
	if msgChan == nil {
		return errors.New("msgChan not set up")
	}
	resultStr := fmt.Sprintf("table@%s %dKB %s %s", imgUrl, (size+1)/1024, result, saveName) //size+1é¿å…0ä½œé™¤æ•°
	sendMsgMutex.Lock()
	logs.Debug("sendResult:   %s", resultStr)
	(*msgChan) <- resultStr
	sendMsgMutex.Unlock()
	return nil
}

//å‘qtç«¯å‘é€æ¶ˆæ¯ï¼Œè¾¾åˆ°æ§åˆ¶ç»„ä»¶æˆ–æ¶ˆæ¯æ˜¾ç¤ºç­‰ç›®çš„
func sendMessage(key, content string) error {
	if key == "" || content == "" {
		return errors.New("key or content is null string")
	}
	if strings.Contains(key, "@") {
		return errors.New("key or content contain '@'")
	}
	resultStr := fmt.Sprintf("%s@%s", key, content)
	sendMsgMutex.Lock()
	logs.Debug("sendMessage:   %s", resultStr)
	(*msgChan) <- resultStr
	sendMsgMutex.Unlock()
	return nil
}

//============== åˆ¤æ–­ä¸æ£€æŸ¥ä»£ç  =============

//æ£€éªŒä¸€ä¸ªurlï¼Œä¸”å°†ç›¸å¯¹åœ°å€è½¬æ¢ä¸ºç»å¯¹åœ°å€,è‹¥æœ‰ä¸­æ–‡ç»è¿‡è½¬ç å°†ä¼šè¢«è¿˜åŸ ğŸ“‡
func CheckUrlAndConver(baseUrl string, targetUrl *string) error {
	if baseUrl == "" {
		return errors.New("baseUrl is empty")
	}
	if targetUrl == nil {
		return errors.New("targetUrl is nil")
	}
	target, err := url.Parse(*targetUrl)
	if err != nil {
		return err
	}
	//å°†ç»è¿‡è½¬ç çš„URLå­—ç¬¦ä¸²è¿˜åŸ
	if converLink, err := url.QueryUnescape(*targetUrl); err != nil {
		logs.Warn("QueryUnescape url %s fail: err=%d", *targetUrl, err)
	} else {
		*targetUrl = converLink
	}
	//å»é™¤è¡¨ç¤ºä½ç½®çš„å†…å®¹
	if idx := strings.Index(*targetUrl, "#"); idx > 0 {
		*targetUrl = (*targetUrl)[0 : idx+1]
	}
	//è‹¥æœ¬èº«ä¸ºç»å¯¹è·¯å¾„åˆ™æ— éœ€ç»§ç»­
	if target.IsAbs() {
		return nil
	}
	base, err := url.Parse(baseUrl)
	if err != nil {
		return fmt.Errorf("BaseUrl not right. err=%v", err)
	}
	if !base.IsAbs() {
		return errors.New("BaseUrl is not absolute url")
	}
	*targetUrl = fmt.Sprintf("%s://%s%s", base.Scheme, base.Host, target.Path)
	return nil
}

//æ£€æŸ¥æ˜¯å¦å·²åˆ°è¾¾åº”è¯¥ç»“æŸä»»åŠ¡çš„æ¡ä»¶
func isShouldSopt() bool {
	if diggerState == 0 {
		return true
	}
	if totalBytes >= totalSizeLimit<<20 { //ä¸‹è½½æ€»å¤§å°åˆ°è¾¾ä¸Šé™
		logs.Info("total size of download files reach the limit")
		return true
	}
	if pageNumber >= pageLimit { //è®¿é—®é¡µé¢æ•°é‡åˆ°è¾¾ä¸Šé™
		logs.Info("total page reach the limit")
		return true
	}
	if totalNumber >= numberLimit { //ä¸‹è½½æ•°é‡åˆ°è¾¾ä¸Šé™
		logs.Info("total numbers of download files reach the limit")
		return true
	}
	//todo ç­‰å¾…æ—¶é—´åˆ°è¾¾ä¸Šé™
	return false
}

//åˆ¤æ–­ baseurl æ ¼å¼æ˜¯å¦æ­£ç¡®å¯ç”¨
func isBaseUrlRight(baseurl string) bool {
	regHttpUrl := regexp.MustCompile(`https?://[^ "]*`)
	return regHttpUrl.MatchString(baseUrl)
}

//æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨  ğŸ“‚
func checkDirExist(dir string) bool {
	info, err := os.Stat(dir)
	if err != nil {
		if !os.IsNotExist(err) {
			logs.Error("error with file exist: %v", err)
		}
		return false
	}
	return info.IsDir()
}

//æ£€æŸ¥ä¸é…ç½®ç›¸å…³çš„å…¨å±€å˜é‡ï¼Œè¿”å›æ£€æŸ¥ç»“æœ, ä¸€äº›ç‰¹å®šçš„éæ³•å€¼è¢«è®¾ç½®æˆé»˜è®¤å€¼è€ŒéæŠ¥é”™
func checkBaseConf() bool {
	if method != "BFS" && method != "DFS" && method != "FOR" && method != "LIST" {
		logs.Warn("config 'method' not right. method=%s", method)
		return false
	}
	if savePath == "" || checkDirExist(savePath) == false {
		logs.Warn("config 'savepath' not right. savePath=%s", savePath)
		return false
	}
	if totalSizeLimit <= 0 || totalSizeLimit > 100<<20 { //100GB
		logs.Warn("config 'totalSizeLimit' not right. totalSizeLimit=%d", totalSizeLimit)
		return false
	}
	if numberLimit <= 0 {
		logs.Warn("config 'numberLimit' erase from %d to 1", numberLimit)
		numberLimit = 1
	} else if numberLimit > 1000000 {
		logs.Warn("config 'numberLimit' erase from %d to 1000000", numberLimit)
		numberLimit = 1000000
	}
	if threadLimit <= 0 {
		logs.Warn("config 'threadLimit' erase from %d to 1", threadLimit)
		threadLimit = 1
	} else if threadLimit > 20 {
		logs.Warn("config 'threadLimit' erase from %d to 20", threadLimit)
		threadLimit = 20
	}
	if minSizeLimit < 0 {
		logs.Warn("config 'minSizeLimit' erase from %d to 0", minSizeLimit)
		minSizeLimit = 20
	}
	if maxSizeLimit < 0 || maxSizeLimit > 10240 { //100MB
		logs.Warn("config 'maxSizeLimit' erase from %d to 10240", maxSizeLimit)
		minSizeLimit = 20
	}
	if waitTimeLimit < 0 || waitTimeLimit > 10000 {
		logs.Warn("config 'waitTimeLimit' erase from %d to 0", waitTimeLimit)
		waitTimeLimit = 0
	}
	if intervalTime < 0 || intervalTime > 10000 {
		logs.Warn("config 'intervalTime' erase from %d to 0", intervalTime)
		intervalTime = 0
	}
	if isBaseUrlRight(baseUrl) == false {
		logs.Warn("config 'baseUrl' not right. baseUrl=%d", baseUrl)
		return false
	}
	if len(linkKey) > 50 {
		logs.Warn("config 'linkKey' is cancel because too long")
		linkKey = ""
	}
	if len(targetKey) > 50 {
		logs.Warn("config 'targetKey' is cancel because too long")
		targetKey = ""
	}
	if method == "FOR" && startPoint > endPoint {
		logs.Warn("config 'startPoint' and 'endPoing' swap value")
		tmp := startPoint
		startPoint = endPoint
		endPoint = tmp
	}
	return true
}

//æ£€æŸ¥æ˜¯å¦èƒ½æ­£å¸¸è®¿é—®baseURLæŒ‡å®šçš„ç¬¬ä¸€ä¸ªç½‘é¡µ,å¯æ£€æµ‹ç½‘ç»œçŠ¶æ€ä»¥åŠBaseUrl
func canVisitBaseUrl() (bool, error) {
	var err error
	if baseUrl == "" {
		err = errors.New("baseUrl is empty")
		logs.Error(err)
		return false, err
	}
	if mainClient == nil {
		err = errors.New("mainClient is null")
		logs.Error(err)
		return false, err
	}
	if resp, err := mainClient.Get(baseUrl); err != nil {
		logs.Warn("test fail: err=%v", err)
		return false, err
	} else if resp.StatusCode != http.StatusOK {
		err = fmt.Errorf("test fail: code=%d  status=%s", resp.StatusCode, resp.Status)
		logs.Warn(err)
		return false, err
	}
	return true, nil
}
